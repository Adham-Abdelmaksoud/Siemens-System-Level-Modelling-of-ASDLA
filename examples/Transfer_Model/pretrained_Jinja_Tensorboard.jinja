# import the necessary packages
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, TensorDataset
from torchvision.datasets import mnist
from torchvision import models, transforms
from torchvision.transforms import v2
from torch.optim import lr_scheduler
from torchvision.transforms import ToTensor
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
import seaborn as sns


# Initialize TensorBoard writer
writer = SummaryWriter()

# initiallization
BATCH_SIZE = {{data.batch_size}}
EPOCHS = {{data.num_epochs}}
TRAIN_SPLIT = 0.75
VAL_SPLIT = 0.15
TEST_SPLIT = 0.1
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = models.{{data.pretrained_model_name}}(weights='DEFAULT')

for name, param in model.named_parameters():
    print(param.shape)
    batch = param.shape[0]
    channels = param.shape[1]
    height = param.shape[2]
    width = param.shape[3]

    # print(batch)
    break

for param in model.parameters():
    param.requires_grad = False
transform = transforms.Compose([
    v2.Resize((height, width)),
    v2.Grayscale(num_output_channels=channels),  # Convert images to RGB format
    # Convert images to PyTorch tensors
    v2.ToImage(), v2.ToDtype(torch.float32, scale=True)
])
train_dataset = mnist.MNIST(root='E:/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/data/MNIST/train',
                            train=True, download=True, transform=transform)
test_dataset = mnist.MNIST(root='E:/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/data/MNIST/test',
                           train=False, download=True, transform=transform)
train_dataloader = DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)
test_dataloader = DataLoader(
    test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)
loss_fn = nn.CrossEntropyLoss()
class_names = train_dataset.classes

# Add model graph to TensorBoard
dummy_input = torch.randn(1, 1, 28, 28).to(device)
writer.add_graph(model, dummy_input)


num_ftrs = model.fc.in_features
print(num_ftrs)
model.fc = nn.Linear(num_ftrs, len(class_names))
model = model.to(device)

# Observe that all parameters are being optimized
optimizer = optim.{{data.optimizer.type}}(model.parameters(), lr={{data.optimizer.lr}}, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
lr_scheduler.


# Parameters of newly constructed modules have requires_grad=True by default


# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

for e in range(0, EPOCHS):
    # print(EPOCHS)
    # set the model in training mode
    model.train()
    # initialize the total training and validation loss
    totalTrainLoss = 0
    totalValLoss = 0
    # initialize the number of correct predictions in the training and validation step
    trainCorrect = 0
    valCorrect = 0
    # loop over the training set
    for (x, y) in train_dataloader:
        # print("hamada")
        # send the input to the device
        (x, y) = (x.to(device), y.to(device))
        # perform a forward pass and calculate the training loss
        pred = model(x)
        loss = loss_fn(pred, y)
        # zero out the gradients, perform the backpropagation step, and update the weights
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        # add the loss to the total training loss so far and calculate the number of correct predictions
        totalTrainLoss += loss
        trainCorrect += (pred.argmax(1) == y).type(
            torch.float).sum().item()
    
    avg_train_loss = totalTrainLoss / len(train_dataloader)
    writer.add_scalar('Loss/Train', avg_train_loss, e)
    writer.add_scalar('Accuracy/Train', trainCorrect / len(train_dataloader.dataset), e)
    
    model.eval()
    print(trainCorrect)

# Visualize final layers
for name, param in model.named_parameters():
    writer.add_histogram(name, param.clone().cpu().data.numpy(), e)

# Visualize model weights
    for name, param in model.named_parameters():
        if 'weight' in name:
            writer.add_histogram(name, param.clone().cpu().data.numpy(), e)


with torch.no_grad():
    model.eval()
    # initialize a list to store our predictions
    preds = []
    testCorrect = 0
    for (x, y) in test_dataloader:
        x = (x.to(device))
        y = (y.to(device))

        pred = model(x)
        preds.extend(pred.argmax(axis=1).cpu().numpy())
        testCorrect += (pred.argmax(1) == y).type(
            torch.float).sum().item()
        print(testCorrect)

    avg_test_accuracy = testCorrect / len(test_dataloader.dataset)
    writer.add_scalar('Accuracy/Test', avg_test_accuracy, 0)

# Save model to ONNX file
dummy_input = torch.randn(1, 1, 28, 28).to(device)
onnx_filename = "model.onnx"
torch.onnx.export(model, dummy_input, onnx_filename)
writer.add_graph_onnx(onnx_filename)

# Close TensorBoard writer
writer.close()


# calculate the training, validation, and test accuracy
trainAccuracy = trainCorrect / len(train_dataloader.dataset)
testAccuracy = testCorrect / len(test_dataloader.dataset)

print("Train Accuracy:", trainAccuracy)
print("Test Accuracy:", testAccuracy)
tensors = torch.jit.script(model)
tensors.save(
    "E:/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/data/result/model6.pt")