# import the necessary packages
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, TensorDataset
from torchvision.datasets import mnist
from torchvision.transforms import ToTensor
from model import CNN
from torch.utils.tensorboard import SummaryWriter
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
import seaborn as sns



# Initialize TensorBoard writer
writer = SummaryWriter()

# initiallization
LR = {{learning_rate}} # <--
BATCH_SIZE = {{batch_size}} # <--
EPOCHS = {{epochs}} # <--
TRAIN_SPLIT = 0.75
VAL_SPLIT = 0.15
TEST_SPLIT = 0.1
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CNN()

train_dataset = mnist.MNIST(root='./train', train=True, download=True, transform=ToTensor())
test_dataset = mnist.MNIST(root='./test', train=False, download=True, transform=ToTensor())
train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
opt = optim.{{optimizer}}(model.parameters(), lr=LR) # <--
lossFn = nn.{{loss_func}}() # <--

# Add model graph to TensorBoard
dummy_input = torch.randn(1, 1, 28, 28).to(device)
writer.add_graph(model, dummy_input)

for e in range(0, EPOCHS):
    model.train()
    totalTrainLoss = 0
    trainCorrect = 0

    for (x, y) in train_dataloader:
        (x, y) = (x.to(device), y.to(device))
        pred = model(x)
        loss = lossFn(pred, y)

        opt.zero_grad()
        loss.backward()
        opt.step()

        totalTrainLoss += loss
        trainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()

    avg_train_loss = totalTrainLoss / len(train_dataloader)
    writer.add_scalar('Loss/Train', avg_train_loss, e)
    writer.add_scalar('Accuracy/Train', trainCorrect / len(train_dataloader.dataset), e)

# Visualize final layers
for name, param in model.named_parameters():
    writer.add_histogram(name, param.clone().cpu().data.numpy(), e)

# Visualize model weights
for name, param in model.named_parameters():
    if 'weight' in name:
        writer.add_histogram(name, param.clone().cpu().data.numpy(), e)

model.eval()

with torch.no_grad():
    model.eval()
    preds = []
    testCorrect = 0

    for (x, y) in test_dataloader:
        x = x.to(device)
        pred = model(x)
        preds.extend(pred.argmax(axis=1).cpu().numpy())
        testCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()

    avg_test_accuracy = testCorrect / len(test_dataloader.dataset)
    writer.add_scalar('Accuracy/Test', avg_test_accuracy, 0)

# Save model to ONNX file
dummy_input = torch.randn(1, 1, 28, 28).to(device)
onnx_filename = "model.onnx"
torch.onnx.export(model, dummy_input, onnx_filename)
writer.add_graph_onnx(onnx_filename)

# Close TensorBoard writer
writer.close()

# Print final accuracy
print("Final Test Accuracy:", avg_test_accuracy)

# Calculate the training, validation, and test accuracy
trainAccuracy = trainCorrect / len(train_dataloader.dataset)
testAccuracy = testCorrect / len(test_dataloader.dataset)

print("Train Accuracy:", trainAccuracy)
print("Test Accuracy:", testAccuracy)

torch.save(model, "model.pt")