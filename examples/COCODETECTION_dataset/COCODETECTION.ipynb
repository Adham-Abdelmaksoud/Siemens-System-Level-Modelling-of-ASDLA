{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates how to load the COCO dataset using torchvision in PyTorch and access its elements (images and annotations) for further processing or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the training dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "train_df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "train_df.info()\n",
    "\n",
    "# Visualize the distribution of the 'Survived' variable\n",
    "sns.countplot(x='Survived', data=train_df)\n",
    "plt.title('Distribution of Survival')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "\n",
    "# Display missing values\n",
    "missing_values\n",
    "\n",
    "# Display basic statistics of numerical features\n",
    "statistics_summary = train_df.describe()\n",
    "\n",
    "# Display basic statistics of categorical features\n",
    "categorical_summary = train_df.describe(include=['object'])\n",
    "\n",
    "# Explore the distribution of 'Age' using a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['Age'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the survival distribution by gender\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Survived', hue='Sex', data=train_df)\n",
    "plt.title('Survival Distribution by Gender')\n",
    "plt.xlabel('Survived')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Sex')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the survival distribution by passenger class\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Survived', hue='Pclass', data=train_df)\n",
    "plt.title('Survival Distribution by Passenger Class')\n",
    "plt.xlabel('Survived')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Pclass')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values before handling\n",
    "missing_values_before = train_df.isnull().sum()\n",
    "missing_values_before = missing_values_before[missing_values_before > 0].sort_values(ascending=False)\n",
    "\n",
    "# Display missing values before handling\n",
    "missing_values_before\n",
    "\n",
    "# Impute missing values for 'Age' using the median\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Impute missing values for 'Embarked' using the mode\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop 'Cabin' column due to a large number of missing values\n",
    "train_df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# Drop irrelevant features: 'PassengerId', 'Name', 'Ticket'\n",
    "train_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Check for missing values after handling\n",
    "missing_values_after = train_df.isnull().sum()\n",
    "missing_values_after = missing_values_after[missing_values_after > 0].sort_values(ascending=False)\n",
    "\n",
    "# Display missing values after handling\n",
    "missing_values_after\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "# Create a new feature 'FamilySize' by combining 'SibSp' and 'Parch'\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "\n",
    "# Create a new feature 'IsAlone' indicating whether the passenger is traveling alone\n",
    "train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype('int')\n",
    "\n",
    "# Display the dataset with new features\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "# Convert categorical variable 'Pclass' into one-hot encoded vectors\n",
    "pclass_dummies = pd.get_dummies(train_df['Pclass'], prefix='Pclass')\n",
    "train_df = pd.concat([train_df, pclass_dummies], axis=1)\n",
    "train_df.drop('Pclass', axis=1, inplace=True)\n",
    "\n",
    "# Display the dataset with one-hot encoded vectors\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1,1,10,100,500,1000],\n",
    "    'kernel': ['linear','poly','rbf'],\n",
    "    'gamma': ['scale']##missing auto\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Update the classifier with the best hyperparameters\n",
    "best_svm_classifier = SVC(C=best_params['C'], kernel=best_params['kernel'], gamma=best_params['gamma'])\n",
    "\n",
    "# Train the classifier on the entire training dataset\n",
    "best_svm_classifier.fit(X, y)\n",
    "\n",
    "\n",
    "# Print the parameters of the trained SVM classifier\n",
    "print(\"Parameters of the trained SVM classifier:\")\n",
    "print(best_svm_classifier.get_params())\n",
    "\n",
    "\n",
    "\n",
    "# Extract results of hyperparameter tuning\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Plot the mean test scores for each combination of hyperparameters\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='param_C', y='mean_test_score', hue='param_kernel', data=results, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.title('Hyperparameter Tuning for SVM')\n",
    "plt.xlabel('C (Regularization Parameter)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_knn = GridSearchCV(knn_classifier, param_grid_knn, cv=8, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search_knn.fit(X, y)\n",
    "\n",
    "# Extract the results from the grid search\n",
    "results_knn = pd.DataFrame(grid_search_knn.cv_results_)\n",
    "\n",
    "# Display the best hyperparameters for KNN\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "print(f\"Best Hyperparameters for KNN: {best_params_knn}\")\n",
    "\n",
    "# Update the KNN classifier with the best hyperparameters\n",
    "best_knn_classifier = KNeighborsClassifier(n_neighbors=best_params_knn['n_neighbors'],\n",
    "                                           weights=best_params_knn['weights'],\n",
    "                                           algorithm=best_params_knn['algorithm'],\n",
    "                                           metric=best_params_knn['metric'])\n",
    "\n",
    "# Train the classifier on the entire training dataset\n",
    "best_knn_classifier.fit(X, y)\n",
    "\n",
    "# Print the parameters of the trained SVM classifier\n",
    "print(\"Parameters of the trained SVM classifier:\")\n",
    "print(best_knn_classifier.get_params())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the process of hyperparameter tuning\n",
    "\n",
    "# Plot for 'metric'\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='param_n_neighbors', y='mean_test_score', hue='param_metric', data=results_knn, marker='o')\n",
    "plt.title('Hyperparameter Tuning for KNN - Metric')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='distance')\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'n_neighbors'\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='param_n_neighbors', y='mean_test_score', hue='param_weights', data=results_knn, marker='o')\n",
    "plt.title('Hyperparameter Tuning for KNN - Number of Neighbors')\n",
    "plt.xlabel('Number of Neighbors (n_neighbors)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Weights')\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'algorithm'\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='param_n_neighbors', y='mean_test_score', hue='param_algorithm', data=results_knn, marker='o')\n",
    "plt.title('Hyperparameter Tuning for KNN - Algorithm')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='algorithms')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'X' and 'y' are already defined from your dataset\n",
    "# Separate features (X) and target variable (y)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "bayes_classifier = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_bayes = {\n",
    "    'var_smoothing': [ 0.1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_bayes = GridSearchCV(bayes_classifier, param_grid_bayes, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search_bayes.fit(X, y)\n",
    "\n",
    "# Display the best hyperparameters for Bayesian classifier\n",
    "best_params_bayes = grid_search_bayes.best_params_\n",
    "print(f\"Best Hyperparameters for Bayesian Classifier: {best_params_bayes}\")\n",
    "\n",
    "# Update the Bayesian classifier with the best hyperparameters\n",
    "best_bayes_classifier = GaussianNB(var_smoothing=best_params_bayes['var_smoothing'])\n",
    "\n",
    "# Train the classifier on the entire training dataset\n",
    "best_bayes_classifier.fit(X, y)\n",
    "\n",
    "# Visualize the process of hyperparameter tuning\n",
    "results_bayes = pd.DataFrame(grid_search_bayes.cv_results_)\n",
    "\n",
    "\n",
    "# Print the parameters of the trained SVM classifier\n",
    "print(\"Parameters of the trained SVM classifier:\")\n",
    "print(best_bayes_classifier.get_params())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot the mean test scores for each combination of hyperparameters\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='param_var_smoothing', y='mean_test_score', data=results_bayes, marker='o')\n",
    "plt.title('Hyperparameter Tuning for Bayesian Classifier')\n",
    "plt.xlabel('Variance Smoothing (var_smoothing)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Assuming you have the following classifiers available:\n",
    "# svm_classifier, knn_classifier, bayes_classifier, tree_classifier, mlp_classifier\n",
    "\n",
    "classifiers = {\n",
    "    'SVM': best_svm_classifier,\n",
    "    'KNN': best_knn_classifier,\n",
    "    'Naive Bayes': best_bayes_classifier,\n",
    "    'Decision Trees': best_tree_classifier,\n",
    "    'MLP': best_mlp_classifier\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "roc_auc_scores = {}\n",
    "roc_curves = {}\n",
    "\n",
    "# Evaluate each classifier\n",
    "for name, classifier in classifiers.items():\n",
    "    # Fit the model on the training data\n",
    "    #classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on the test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy_scores[name] = accuracy_score(y_test, y_pred)\n",
    "    precision_scores[name] = precision_score(y_test, y_pred)\n",
    "    recall_scores[name] = recall_score(y_test, y_pred)\n",
    "    f1_scores[name] = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # For ROC/AUC, handle binary classifiers\n",
    "    if hasattr(classifier, \"decision_function\"):\n",
    "        y_scores = classifier.decision_function(X_test)\n",
    "    elif hasattr(classifier, \"predict_proba\"):\n",
    "        probas = classifier.predict_proba(X_test)[:, 1]\n",
    "        y_scores = probas\n",
    "    else:\n",
    "        raise ValueError(\"Classifier does not have decision_function or predict_proba.\")\n",
    "    \n",
    "    roc_auc_scores[name] = roc_auc_score(y_test, y_scores)\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_curves[name] = {'fpr': fpr, 'tpr': tpr}\n",
    "\n",
    "# Print or visualize the metrics as needed\n",
    "print(\"Accuracy Scores:\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "print(\"\\nPrecision Scores:\")\n",
    "print(precision_scores)\n",
    "\n",
    "print(\"\\nRecall Scores:\")\n",
    "print(recall_scores)\n",
    "\n",
    "print(\"\\nF1 Scores:\")\n",
    "print(f1_scores)\n",
    "\n",
    "print(\"\\nROC AUC Scores:\")\n",
    "print(roc_auc_scores)\n",
    "\n",
    "# Visualize ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, curve in roc_curves.items():\n",
    "    plt.plot(curve['fpr'], curve['tpr'], label=f'{name} (AUC = {roc_auc_scores[name]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.title('ROC Curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_tree = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.2, 0.5, 0.8],\n",
    "    'max_leaf_nodes': [None, 5, 10, 20, 50],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_tree = GridSearchCV(tree_classifier, param_grid_tree, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search_tree.fit(X, y)\n",
    "\n",
    "# Display the best hyperparameters for Decision Tree\n",
    "best_params_tree = grid_search_tree.best_params_\n",
    "print(f\"Best Hyperparameters for Decision Tree: {best_params_tree}\")\n",
    "\n",
    "# Update the Decision Tree classifier with the best hyperparameters\n",
    "best_tree_classifier = DecisionTreeClassifier(criterion=best_params_tree['criterion'],\n",
    "                                              splitter=best_params_tree['splitter'],\n",
    "                                              max_depth=best_params_tree['max_depth'],\n",
    "                                              min_samples_split=best_params_tree['min_samples_split'],\n",
    "                                              min_samples_leaf=best_params_tree['min_samples_leaf'],\n",
    "                                              max_features=best_params_tree['max_features'],\n",
    "                                              max_leaf_nodes=best_params_tree['max_leaf_nodes'],\n",
    "                                              min_impurity_decrease=best_params_tree['min_impurity_decrease'])\n",
    "\n",
    "# Train the classifier on the entire training dataset\n",
    "best_tree_classifier.fit(X, y)\n",
    "\n",
    "# Assuming best_svm_classifier is already defined and trained\n",
    "\n",
    "# Print the parameters of the trained SVM classifier\n",
    "print(\"Parameters of the trained SVM classifier:\")\n",
    "print(best_tree_classifier.get_params())\n",
    "\n",
    "\n",
    "# Visualize the process of hyperparameter tuning\n",
    "results_tree = pd.DataFrame(grid_search_tree.cv_results_)\n",
    "\n",
    "\n",
    "\n",
    "# Additional visualizations\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Convert 'None' values to a string for visualization\n",
    "results_tree['param_max_depth'] = results_tree['param_max_depth'].astype(str)\n",
    "results_tree['param_min_samples_split'] = results_tree['param_min_samples_split'].astype(str)\n",
    "results_tree['param_max_features'] = results_tree['param_max_features'].astype(str)\n",
    "results_tree['param_max_leaf_nodes'] = results_tree['param_max_leaf_nodes'].astype(str)\n",
    "\n",
    "# Plot 1: Min Samples Split \n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='param_min_samples_split', y='mean_test_score', hue='param_criterion', data=results_tree)\n",
    "plt.title('Hyperparameter Tuning for Decision Tree')\n",
    "plt.xlabel('Min Samples Split (min_samples_split)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Criterion')\n",
    "\n",
    "# Plot 2: Max Features \n",
    "plt.subplot(2, 2, 2)\n",
    "sns.pointplot(x='param_max_features', y='mean_test_score', hue='param_criterion', data=results_tree, dodge=True, markers=['o', 's'])\n",
    "plt.title('Hyperparameter Tuning for Decision Tree')\n",
    "plt.xlabel('Max Features (max_features)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Criterion')\n",
    "\n",
    "# Plot 3: Max Leaf Nodes \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='param_max_leaf_nodes', y='mean_test_score', hue='param_criterion', data=results_tree)\n",
    "plt.title('Hyperparameter Tuning for Decision Tree')\n",
    "plt.xlabel('Max Leaf Nodes (max_leaf_nodes)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Criterion')\n",
    "\n",
    "# Plot3: Max depth \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.lineplot(x='param_max_depth', y='mean_test_score', hue='param_criterion', data=results_tree, marker='o')\n",
    "plt.title('Hyperparameter Tuning for Decision Tree')\n",
    "plt.xlabel('Max Depth (max_depth)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Criterion')\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'X' and 'y' are already defined from your dataset\n",
    "# Separate features (X) and target variable (y)\n",
    "\n",
    "# Create an MLP (Multi-Layer Perceptron) classifier\n",
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_mlp = GridSearchCV(mlp_classifier, param_grid_mlp, cv=2, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search_mlp.fit(X, y)\n",
    "\n",
    "# Display the best hyperparameters for MLP\n",
    "best_params_mlp = grid_search_mlp.best_params_\n",
    "print(f\"Best Hyperparameters for MLP: {best_params_mlp}\")\n",
    "\n",
    "# Update the MLP classifier with the best hyperparameters\n",
    "best_mlp_classifier = MLPClassifier(hidden_layer_sizes=best_params_mlp['hidden_layer_sizes'],\n",
    "                                    activation=best_params_mlp['activation'],\n",
    "                                    alpha=best_params_mlp['alpha'],\n",
    "                                    learning_rate=best_params_mlp['learning_rate'],\n",
    "                                    max_iter=best_params_mlp['max_iter'],\n",
    "                                    learning_rate_init=best_params_mlp['learning_rate_init'])\n",
    "\n",
    "# Train the classifier on the entire training dataset\n",
    "best_mlp_classifier.fit(X, y)\n",
    "\n",
    "\n",
    "# Print the parameters of the trained SVM classifier\n",
    "print(\"Parameters of the trained SVM classifier:\")\n",
    "print(best_mlp_classifier.get_params())\n",
    "\n",
    "\n",
    "# Visualize the process of hyperparameter tuning (example plot)\n",
    "results_mlp = pd.DataFrame(grid_search_mlp.cv_results_)\n",
    "\n",
    "# Print unique values in 'param_hidden_layer_sizes' column\n",
    "unique_values = results_mlp['param_hidden_layer_sizes'].unique()\n",
    "print(\"Unique values in 'param_hidden_layer_sizes':\", unique_values)\n",
    "\n",
    "\n",
    "# Convert 'param_hidden_layer_sizes' to numeric\n",
    "results_mlp['param_hidden_layer_sizes'] = results_mlp['param_hidden_layer_sizes'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "results_mlp['param_hidden_layer_sizes'] = pd.to_numeric(results_mlp['param_hidden_layer_sizes'], errors='coerce')\n",
    "\n",
    "# Visualize the process of hyperparameter tuning (example plot)\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_hidden_layer_sizes', y='mean_test_score', hue='param_activation', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Hidden Layer Sizes (hidden_layer_sizes)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Activation Function')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the process of hyperparameter tuning for a different plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_alpha', y='mean_test_score', hue='param_learning_rate', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('learning rate')\n",
    "plt.legend(title='Activation Function')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_alpha', y='mean_test_score', hue='param_activation', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Alpha (param_alpha)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Activation Function')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_learning_rate', y='mean_test_score', hue='param_activation', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Learning Rate (param_learning_rate)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Activation Function')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_hidden_layer_sizes', y='mean_test_score', hue='param_alpha', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Hidden Layer Sizes (param_hidden_layer_sizes)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Alpha')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_learning_rate_init', y='mean_test_score', hue='param_activation', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Learning Rate Init (param_learning_rate_init)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Activation Function')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_max_iter', y='mean_test_score', hue='param_alpha', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Max Iterations (param_max_iter)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Alpha')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(x='param_alpha', y='mean_test_score', hue='param_learning_rate_init', data=results_mlp, marker='o')\n",
    "plt.title('Hyperparameter Tuning for MLP')\n",
    "plt.xlabel('Alpha (param_alpha)')\n",
    "plt.ylabel('Mean Test Score (Accuracy)')\n",
    "plt.legend(title='Learning Rate init')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\python311\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python311\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
