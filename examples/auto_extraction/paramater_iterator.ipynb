{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramater Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on datasets\n",
    "printing all the names of datasets availeble in torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10\n",
      "CIFAR100\n",
      "CLEVRClassification\n",
      "CREStereo\n",
      "Caltech101\n",
      "Caltech256\n",
      "CarlaStereo\n",
      "CelebA\n",
      "Cityscapes\n",
      "CocoCaptions\n",
      "CocoDetection\n",
      "Country211\n",
      "DTD\n",
      "DatasetFolder\n",
      "EMNIST\n",
      "ETH3DStereo\n",
      "EuroSAT\n",
      "FER2013\n",
      "FGVCAircraft\n",
      "FakeData\n",
      "FallingThingsStereo\n",
      "FashionMNIST\n",
      "Flickr30k\n",
      "Flickr8k\n",
      "Flowers102\n",
      "FlyingChairs\n",
      "FlyingThings3D\n",
      "Food101\n",
      "GTSRB\n",
      "HD1K\n",
      "HMDB51\n",
      "INaturalist\n",
      "ImageFolder\n",
      "ImageNet\n",
      "InStereo2k\n",
      "KMNIST\n",
      "Kinetics\n",
      "Kitti\n",
      "Kitti2012Stereo\n",
      "Kitti2015Stereo\n",
      "KittiFlow\n",
      "LFWPairs\n",
      "LFWPeople\n",
      "LSUN\n",
      "LSUNClass\n",
      "MNIST\n",
      "Middlebury2014Stereo\n",
      "MovingMNIST\n",
      "Omniglot\n",
      "OxfordIIITPet\n",
      "PCAM\n",
      "PhotoTour\n",
      "Places365\n",
      "QMNIST\n",
      "RenderedSST2\n",
      "SBDataset\n",
      "SBU\n",
      "SEMEION\n",
      "STL10\n",
      "SUN397\n",
      "SVHN\n",
      "SceneFlowStereo\n",
      "Sintel\n",
      "SintelStereo\n",
      "StanfordCars\n",
      "UCF101\n",
      "USPS\n",
      "VOCDetection\n",
      "VOCSegmentation\n",
      "VisionDataset\n",
      "WIDERFace\n",
      "__all__\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__getattr__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__path__\n",
      "__spec__\n",
      "_optical_flow\n",
      "_stereo_matching\n",
      "caltech\n",
      "celeba\n",
      "cifar\n",
      "cityscapes\n",
      "clevr\n",
      "coco\n",
      "country211\n",
      "dtd\n",
      "eurosat\n",
      "fakedata\n",
      "fer2013\n",
      "fgvc_aircraft\n",
      "flickr\n",
      "flowers102\n",
      "folder\n",
      "food101\n",
      "gtsrb\n",
      "hmdb51\n",
      "imagenet\n",
      "inaturalist\n",
      "kinetics\n",
      "kitti\n",
      "lfw\n",
      "lsun\n",
      "mnist\n",
      "moving_mnist\n",
      "omniglot\n",
      "oxford_iiit_pet\n",
      "pcam\n",
      "phototour\n",
      "places365\n",
      "rendered_sst2\n",
      "sbd\n",
      "sbu\n",
      "semeion\n",
      "stanford_cars\n",
      "stl10\n",
      "sun397\n",
      "svhn\n",
      "ucf101\n",
      "usps\n",
      "utils\n",
      "video_utils\n",
      "vision\n",
      "voc\n",
      "widerface\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as TVD\n",
    "itt=dir(TVD)\n",
    "for i in itt:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool1d\n",
      "AdaptiveAvgPool2d\n",
      "AdaptiveAvgPool3d\n",
      "AdaptiveLogSoftmaxWithLoss\n",
      "AdaptiveMaxPool1d\n",
      "AdaptiveMaxPool2d\n",
      "AdaptiveMaxPool3d\n",
      "AlphaDropout\n",
      "AvgPool1d\n",
      "AvgPool2d\n",
      "AvgPool3d\n",
      "BCELoss\n",
      "BCEWithLogitsLoss\n",
      "BatchNorm1d\n",
      "BatchNorm2d\n",
      "BatchNorm3d\n",
      "Bilinear\n",
      "CELU\n",
      "CTCLoss\n",
      "ChannelShuffle\n",
      "CircularPad1d\n",
      "CircularPad2d\n",
      "CircularPad3d\n",
      "ConstantPad1d\n",
      "ConstantPad2d\n",
      "ConstantPad3d\n",
      "Container\n",
      "Conv1d\n",
      "Conv2d\n",
      "Conv3d\n",
      "ConvTranspose1d\n",
      "ConvTranspose2d\n",
      "ConvTranspose3d\n",
      "CosineEmbeddingLoss\n",
      "CosineSimilarity\n",
      "CrossEntropyLoss\n",
      "CrossMapLRN2d\n",
      "DataParallel\n",
      "Dropout\n",
      "Dropout1d\n",
      "Dropout2d\n",
      "Dropout3d\n",
      "ELU\n",
      "Embedding\n",
      "EmbeddingBag\n",
      "FeatureAlphaDropout\n",
      "Flatten\n",
      "Fold\n",
      "FractionalMaxPool2d\n",
      "FractionalMaxPool3d\n",
      "GELU\n",
      "GLU\n",
      "GRU\n",
      "GRUCell\n",
      "GaussianNLLLoss\n",
      "GroupNorm\n",
      "Hardshrink\n",
      "Hardsigmoid\n",
      "Hardswish\n",
      "Hardtanh\n",
      "HingeEmbeddingLoss\n",
      "HuberLoss\n",
      "Identity\n",
      "InstanceNorm1d\n",
      "InstanceNorm2d\n",
      "InstanceNorm3d\n",
      "KLDivLoss\n",
      "L1Loss\n",
      "LPPool1d\n",
      "LPPool2d\n",
      "LSTM\n",
      "LSTMCell\n",
      "LayerNorm\n",
      "LazyBatchNorm1d\n",
      "LazyBatchNorm2d\n",
      "LazyBatchNorm3d\n",
      "LazyConv1d\n",
      "LazyConv2d\n",
      "LazyConv3d\n",
      "LazyConvTranspose1d\n",
      "LazyConvTranspose2d\n",
      "LazyConvTranspose3d\n",
      "LazyInstanceNorm1d\n",
      "LazyInstanceNorm2d\n",
      "LazyInstanceNorm3d\n",
      "LazyLinear\n",
      "LeakyReLU\n",
      "Linear\n",
      "LocalResponseNorm\n",
      "LogSigmoid\n",
      "LogSoftmax\n",
      "MSELoss\n",
      "MarginRankingLoss\n",
      "MaxPool1d\n",
      "MaxPool2d\n",
      "MaxPool3d\n",
      "MaxUnpool1d\n",
      "MaxUnpool2d\n",
      "MaxUnpool3d\n",
      "Mish\n",
      "Module\n",
      "ModuleDict\n",
      "ModuleList\n",
      "MultiLabelMarginLoss\n",
      "MultiLabelSoftMarginLoss\n",
      "MultiMarginLoss\n",
      "MultiheadAttention\n",
      "NLLLoss\n",
      "NLLLoss2d\n",
      "PReLU\n",
      "PairwiseDistance\n",
      "Parameter\n",
      "ParameterDict\n",
      "ParameterList\n",
      "PixelShuffle\n",
      "PixelUnshuffle\n",
      "PoissonNLLLoss\n",
      "RNN\n",
      "RNNBase\n",
      "RNNCell\n",
      "RNNCellBase\n",
      "RReLU\n",
      "ReLU\n",
      "ReLU6\n",
      "ReflectionPad1d\n",
      "ReflectionPad2d\n",
      "ReflectionPad3d\n",
      "ReplicationPad1d\n",
      "ReplicationPad2d\n",
      "ReplicationPad3d\n",
      "SELU\n",
      "Sequential\n",
      "SiLU\n",
      "Sigmoid\n",
      "SmoothL1Loss\n",
      "SoftMarginLoss\n",
      "Softmax\n",
      "Softmax2d\n",
      "Softmin\n",
      "Softplus\n",
      "Softshrink\n",
      "Softsign\n",
      "SyncBatchNorm\n",
      "Tanh\n",
      "Tanhshrink\n",
      "Threshold\n",
      "Transformer\n",
      "TransformerDecoder\n",
      "TransformerDecoderLayer\n",
      "TransformerEncoder\n",
      "TransformerEncoderLayer\n",
      "TripletMarginLoss\n",
      "TripletMarginWithDistanceLoss\n",
      "Unflatten\n",
      "Unfold\n",
      "UninitializedBuffer\n",
      "UninitializedParameter\n",
      "Upsample\n",
      "UpsamplingBilinear2d\n",
      "UpsamplingNearest2d\n",
      "ZeroPad1d\n",
      "ZeroPad2d\n",
      "ZeroPad3d\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__path__\n",
      "__spec__\n",
      "_reduction\n",
      "common_types\n",
      "factory_kwargs\n",
      "functional\n",
      "grad\n",
      "init\n",
      "intrinsic\n",
      "modules\n",
      "parallel\n",
      "parameter\n",
      "qat\n",
      "quantizable\n",
      "quantized\n",
      "utils\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as neuralLayers\n",
    "itt=dir(neuralLayers)\n",
    "for i in itt:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.pooling.AdaptiveAvgPool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AdaptiveAvgPool3d'> ###############\n",
      "<class 'torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss'> ###############\n",
      "<class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AdaptiveMaxPool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AdaptiveMaxPool3d'> ###############\n",
      "<class 'torch.nn.modules.dropout.AlphaDropout'> ###############\n",
      "<class 'torch.nn.modules.pooling.AvgPool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AvgPool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.AvgPool3d'> ###############\n",
      "<class 'torch.nn.modules.loss.BCELoss'> ###############\n",
      "<class 'torch.nn.modules.loss.BCEWithLogitsLoss'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm1d'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm3d'> ###############\n",
      "<class 'torch.nn.modules.linear.Bilinear'> ###############\n",
      "<class 'torch.nn.modules.activation.CELU'> ###############\n",
      "<class 'torch.nn.modules.loss.CTCLoss'> ###############\n",
      "<class 'torch.nn.modules.channelshuffle.ChannelShuffle'> ###############\n",
      "<class 'torch.nn.modules.padding.CircularPad1d'> ###############\n",
      "<class 'torch.nn.modules.padding.CircularPad2d'> ###############\n",
      "<class 'torch.nn.modules.padding.CircularPad3d'> ###############\n",
      "<class 'torch.nn.modules.padding.ConstantPad1d'> ###############\n",
      "<class 'torch.nn.modules.padding.ConstantPad2d'> ###############\n",
      "<class 'torch.nn.modules.padding.ConstantPad3d'> ###############\n",
      "<class 'torch.nn.modules.container.Container'> ###############\n",
      "<class 'torch.nn.modules.conv.Conv1d'> ###############\n",
      "<class 'torch.nn.modules.conv.Conv2d'> ###############\n",
      "<class 'torch.nn.modules.conv.Conv3d'> ###############\n",
      "<class 'torch.nn.modules.conv.ConvTranspose1d'> ###############\n",
      "<class 'torch.nn.modules.conv.ConvTranspose2d'> ###############\n",
      "<class 'torch.nn.modules.conv.ConvTranspose3d'> ###############\n",
      "<class 'torch.nn.modules.loss.CosineEmbeddingLoss'> ###############\n",
      "<class 'torch.nn.modules.distance.CosineSimilarity'> ###############\n",
      "<class 'torch.nn.modules.loss.CrossEntropyLoss'> ###############\n",
      "<class 'torch.nn.modules.normalization.CrossMapLRN2d'> ###############\n",
      "<class 'torch.nn.modules.dropout.Dropout'> ###############\n",
      "<class 'torch.nn.modules.dropout.Dropout1d'> ###############\n",
      "<class 'torch.nn.modules.dropout.Dropout2d'> ###############\n",
      "<class 'torch.nn.modules.dropout.Dropout3d'> ###############\n",
      "<class 'torch.nn.modules.activation.ELU'> ###############\n",
      "<class 'torch.nn.modules.sparse.Embedding'> ###############\n",
      "<class 'torch.nn.modules.sparse.EmbeddingBag'> ###############\n",
      "<class 'torch.nn.modules.dropout.FeatureAlphaDropout'> ###############\n",
      "<class 'torch.nn.modules.flatten.Flatten'> ###############\n",
      "<class 'torch.nn.modules.fold.Fold'> ###############\n",
      "<class 'torch.nn.modules.pooling.FractionalMaxPool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.FractionalMaxPool3d'> ###############\n",
      "<class 'torch.nn.modules.activation.GELU'> ###############\n",
      "<class 'torch.nn.modules.activation.GLU'> ###############\n",
      "<class 'torch.nn.modules.rnn.GRU'> ###############\n",
      "<class 'torch.nn.modules.rnn.GRUCell'> ###############\n",
      "<class 'torch.nn.modules.loss.GaussianNLLLoss'> ###############\n",
      "<class 'torch.nn.modules.normalization.GroupNorm'> ###############\n",
      "<class 'torch.nn.modules.activation.Hardshrink'> ###############\n",
      "<class 'torch.nn.modules.activation.Hardsigmoid'> ###############\n",
      "<class 'torch.nn.modules.activation.Hardswish'> ###############\n",
      "<class 'torch.nn.modules.activation.Hardtanh'> ###############\n",
      "<class 'torch.nn.modules.loss.HingeEmbeddingLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.HuberLoss'> ###############\n",
      "<class 'torch.nn.modules.linear.Identity'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.InstanceNorm1d'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.InstanceNorm2d'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.InstanceNorm3d'> ###############\n",
      "<class 'torch.nn.modules.loss.KLDivLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.L1Loss'> ###############\n",
      "<class 'torch.nn.modules.pooling.LPPool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.LPPool2d'> ###############\n",
      "<class 'torch.nn.modules.rnn.LSTM'> ###############\n",
      "<class 'torch.nn.modules.rnn.LSTMCell'> ###############\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.LazyBatchNorm1d'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.LazyBatchNorm2d'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.LazyBatchNorm3d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConv1d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConv2d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConv3d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConvTranspose1d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConvTranspose2d'> ###############\n",
      "<class 'torch.nn.modules.conv.LazyConvTranspose3d'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.LazyInstanceNorm1d'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.LazyInstanceNorm2d'> ###############\n",
      "<class 'torch.nn.modules.instancenorm.LazyInstanceNorm3d'> ###############\n",
      "<class 'torch.nn.modules.linear.LazyLinear'> ###############\n",
      "<class 'torch.nn.modules.activation.LeakyReLU'> ###############\n",
      "<class 'torch.nn.modules.linear.Linear'> ###############\n",
      "<class 'torch.nn.modules.normalization.LocalResponseNorm'> ###############\n",
      "<class 'torch.nn.modules.activation.LogSigmoid'> ###############\n",
      "<class 'torch.nn.modules.activation.LogSoftmax'> ###############\n",
      "<class 'torch.nn.modules.loss.MSELoss'> ###############\n",
      "<class 'torch.nn.modules.loss.MarginRankingLoss'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxPool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxPool3d'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxUnpool1d'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxUnpool2d'> ###############\n",
      "<class 'torch.nn.modules.pooling.MaxUnpool3d'> ###############\n",
      "<class 'torch.nn.modules.activation.Mish'> ###############\n",
      "<class 'torch.nn.modules.module.Module'> ###############\n",
      "<class 'torch.nn.modules.container.ModuleDict'> ###############\n",
      "<class 'torch.nn.modules.container.ModuleList'> ###############\n",
      "<class 'torch.nn.modules.loss.MultiLabelMarginLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.MultiLabelSoftMarginLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.MultiMarginLoss'> ###############\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'> ###############\n",
      "<class 'torch.nn.modules.loss.NLLLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.NLLLoss2d'> ###############\n",
      "<class 'torch.nn.modules.activation.PReLU'> ###############\n",
      "<class 'torch.nn.modules.distance.PairwiseDistance'> ###############\n",
      "<class 'torch.nn.modules.container.ParameterDict'> ###############\n",
      "<class 'torch.nn.modules.container.ParameterList'> ###############\n",
      "<class 'torch.nn.modules.pixelshuffle.PixelShuffle'> ###############\n",
      "<class 'torch.nn.modules.pixelshuffle.PixelUnshuffle'> ###############\n",
      "<class 'torch.nn.modules.loss.PoissonNLLLoss'> ###############\n",
      "<class 'torch.nn.modules.rnn.RNN'> ###############\n",
      "<class 'torch.nn.modules.rnn.RNNBase'> ###############\n",
      "<class 'torch.nn.modules.rnn.RNNCell'> ###############\n",
      "<class 'torch.nn.modules.rnn.RNNCellBase'> ###############\n",
      "<class 'torch.nn.modules.activation.RReLU'> ###############\n",
      "<class 'torch.nn.modules.activation.ReLU'> ###############\n",
      "<class 'torch.nn.modules.activation.ReLU6'> ###############\n",
      "<class 'torch.nn.modules.padding.ReflectionPad1d'> ###############\n",
      "<class 'torch.nn.modules.padding.ReflectionPad2d'> ###############\n",
      "<class 'torch.nn.modules.padding.ReflectionPad3d'> ###############\n",
      "<class 'torch.nn.modules.padding.ReplicationPad1d'> ###############\n",
      "<class 'torch.nn.modules.padding.ReplicationPad2d'> ###############\n",
      "<class 'torch.nn.modules.padding.ReplicationPad3d'> ###############\n",
      "<class 'torch.nn.modules.activation.SELU'> ###############\n",
      "<class 'torch.nn.modules.container.Sequential'> ###############\n",
      "<class 'torch.nn.modules.activation.SiLU'> ###############\n",
      "<class 'torch.nn.modules.activation.Sigmoid'> ###############\n",
      "<class 'torch.nn.modules.loss.SmoothL1Loss'> ###############\n",
      "<class 'torch.nn.modules.loss.SoftMarginLoss'> ###############\n",
      "<class 'torch.nn.modules.activation.Softmax'> ###############\n",
      "<class 'torch.nn.modules.activation.Softmax2d'> ###############\n",
      "<class 'torch.nn.modules.activation.Softmin'> ###############\n",
      "<class 'torch.nn.modules.activation.Softplus'> ###############\n",
      "<class 'torch.nn.modules.activation.Softshrink'> ###############\n",
      "<class 'torch.nn.modules.activation.Softsign'> ###############\n",
      "<class 'torch.nn.modules.batchnorm.SyncBatchNorm'> ###############\n",
      "<class 'torch.nn.modules.activation.Tanh'> ###############\n",
      "<class 'torch.nn.modules.activation.Tanhshrink'> ###############\n",
      "<class 'torch.nn.modules.activation.Threshold'> ###############\n",
      "<class 'torch.nn.modules.transformer.Transformer'> ###############\n",
      "<class 'torch.nn.modules.transformer.TransformerDecoder'> ###############\n",
      "<class 'torch.nn.modules.transformer.TransformerDecoderLayer'> ###############\n",
      "<class 'torch.nn.modules.transformer.TransformerEncoder'> ###############\n",
      "<class 'torch.nn.modules.transformer.TransformerEncoderLayer'> ###############\n",
      "<class 'torch.nn.modules.loss.TripletMarginLoss'> ###############\n",
      "<class 'torch.nn.modules.loss.TripletMarginWithDistanceLoss'> ###############\n",
      "<class 'torch.nn.modules.flatten.Unflatten'> ###############\n",
      "<class 'torch.nn.modules.fold.Unfold'> ###############\n",
      "<class 'torch.nn.modules.upsampling.Upsample'> ###############\n",
      "<class 'torch.nn.modules.upsampling.UpsamplingBilinear2d'> ###############\n",
      "<class 'torch.nn.modules.upsampling.UpsamplingNearest2d'> ###############\n",
      "<class 'torch.nn.modules.padding.ZeroPad1d'> ###############\n",
      "<class 'torch.nn.modules.padding.ZeroPad2d'> ###############\n",
      "<class 'torch.nn.modules.padding.ZeroPad3d'> ###############\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Github\\Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project\\examples\\auto_extraction\\paramater_iterator.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(Conv1d)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(Sequential)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(modules):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mgetattr\u001b[39m(modules,i), modules\u001b[39m.\u001b[39mModule):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mgetattr\u001b[39m(modules,i),\u001b[39m\"\u001b[39m\u001b[39m###############\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# if not(i in dir(contain)):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Github/Siemens-System-Level-Modelling-of-ASDLA-Graduation-Project/examples/auto_extraction/paramater_iterator.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#     print(i)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "from torch.nn import Sequential,Conv1d\n",
    "import torch.nn.modules.container as contain\n",
    "\n",
    "import torch.nn.modules as modules\n",
    "\n",
    "# print(Conv1d)\n",
    "# print(Sequential)\n",
    "for i in dir(modules):\n",
    "    if issubclass(getattr(modules,i), modules.Module):\n",
    "        print(getattr(modules,i),\"###############\")\n",
    "\n",
    "    # if not(i in dir(contain)):\n",
    "    #     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool1d\n",
      "AdaptiveAvgPool2d\n",
      "AdaptiveAvgPool3d\n",
      "AdaptiveLogSoftmaxWithLoss\n",
      "AdaptiveMaxPool1d\n",
      "AdaptiveMaxPool2d\n",
      "AdaptiveMaxPool3d\n",
      "AlphaDropout\n",
      "AvgPool1d\n",
      "AvgPool2d\n",
      "AvgPool3d\n",
      "BCELoss\n",
      "BCEWithLogitsLoss\n",
      "BatchNorm1d\n",
      "BatchNorm2d\n",
      "BatchNorm3d\n",
      "Bilinear\n",
      "CELU\n",
      "CTCLoss\n",
      "ChannelShuffle\n",
      "CircularPad1d\n",
      "CircularPad2d\n",
      "CircularPad3d\n",
      "ConstantPad1d\n",
      "ConstantPad2d\n",
      "ConstantPad3d\n",
      "Container\n",
      "Conv1d\n",
      "Conv2d\n",
      "Conv3d\n",
      "ConvTranspose1d\n",
      "ConvTranspose2d\n",
      "ConvTranspose3d\n",
      "CosineEmbeddingLoss\n",
      "CosineSimilarity\n",
      "CrossEntropyLoss\n",
      "CrossMapLRN2d\n",
      "DataParallel\n",
      "Dropout\n",
      "Dropout1d\n",
      "Dropout2d\n",
      "Dropout3d\n",
      "ELU\n",
      "Embedding\n",
      "EmbeddingBag\n",
      "FeatureAlphaDropout\n",
      "Flatten\n",
      "Fold\n",
      "FractionalMaxPool2d\n",
      "FractionalMaxPool3d\n",
      "GELU\n",
      "GLU\n",
      "GRU\n",
      "GRUCell\n",
      "GaussianNLLLoss\n",
      "GroupNorm\n",
      "Hardshrink\n",
      "Hardsigmoid\n",
      "Hardswish\n",
      "Hardtanh\n",
      "HingeEmbeddingLoss\n",
      "HuberLoss\n",
      "Identity\n",
      "InstanceNorm1d\n",
      "InstanceNorm2d\n",
      "InstanceNorm3d\n",
      "KLDivLoss\n",
      "L1Loss\n",
      "LPPool1d\n",
      "LPPool2d\n",
      "LSTM\n",
      "LSTMCell\n",
      "LayerNorm\n",
      "LazyBatchNorm1d\n",
      "LazyBatchNorm2d\n",
      "LazyBatchNorm3d\n",
      "LazyConv1d\n",
      "LazyConv2d\n",
      "LazyConv3d\n",
      "LazyConvTranspose1d\n",
      "LazyConvTranspose2d\n",
      "LazyConvTranspose3d\n",
      "LazyInstanceNorm1d\n",
      "LazyInstanceNorm2d\n",
      "LazyInstanceNorm3d\n",
      "LazyLinear\n",
      "LeakyReLU\n",
      "Linear\n",
      "LocalResponseNorm\n",
      "LogSigmoid\n",
      "LogSoftmax\n",
      "MSELoss\n",
      "MarginRankingLoss\n",
      "MaxPool1d\n",
      "MaxPool2d\n",
      "MaxPool3d\n",
      "MaxUnpool1d\n",
      "MaxUnpool2d\n",
      "MaxUnpool3d\n",
      "Mish\n",
      "ModuleDict\n",
      "ModuleList\n",
      "MultiLabelMarginLoss\n",
      "MultiLabelSoftMarginLoss\n",
      "MultiMarginLoss\n",
      "MultiheadAttention\n",
      "NLLLoss\n",
      "NLLLoss2d\n",
      "PReLU\n",
      "PairwiseDistance\n",
      "ParameterDict\n",
      "ParameterList\n",
      "PixelShuffle\n",
      "PixelUnshuffle\n",
      "PoissonNLLLoss\n",
      "RNN\n",
      "RNNBase\n",
      "RNNCell\n",
      "RNNCellBase\n",
      "RReLU\n",
      "ReLU\n",
      "ReLU6\n",
      "ReflectionPad1d\n",
      "ReflectionPad2d\n",
      "ReflectionPad3d\n",
      "ReplicationPad1d\n",
      "ReplicationPad2d\n",
      "ReplicationPad3d\n",
      "SELU\n",
      "Sequential\n",
      "SiLU\n",
      "Sigmoid\n",
      "SmoothL1Loss\n",
      "SoftMarginLoss\n",
      "Softmax\n",
      "Softmax2d\n",
      "Softmin\n",
      "Softplus\n",
      "Softshrink\n",
      "Softsign\n",
      "SyncBatchNorm\n",
      "Tanh\n",
      "Tanhshrink\n",
      "Threshold\n",
      "Transformer\n",
      "TransformerDecoder\n",
      "TransformerDecoderLayer\n",
      "TransformerEncoder\n",
      "TransformerEncoderLayer\n",
      "TripletMarginLoss\n",
      "TripletMarginWithDistanceLoss\n",
      "Unflatten\n",
      "Unfold\n",
      "Upsample\n",
      "UpsamplingBilinear2d\n",
      "UpsamplingNearest2d\n",
      "ZeroPad1d\n",
      "ZeroPad2d\n",
      "ZeroPad3d\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as neuralLayers\n",
    "\n",
    "N = dir(neuralLayers)\n",
    "\n",
    "for i in N:\n",
    "    obj = getattr(neuralLayers, i)\n",
    "    if isinstance(obj, type) and obj is not neuralLayers.Module and issubclass(obj, neuralLayers.Module):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_destination\n",
      "__annotations__\n",
      "__call__\n",
      "__class__\n",
      "__constants__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattr__\n",
      "__getattribute__\n",
      "__getstate__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__setstate__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_apply\n",
      "_call_impl\n",
      "_compiled_call_impl\n",
      "_conv_forward\n",
      "_get_backward_hooks\n",
      "_get_backward_pre_hooks\n",
      "_get_name\n",
      "_load_from_state_dict\n",
      "_maybe_warn_non_full_backward_hook\n",
      "_named_members\n",
      "_register_load_state_dict_pre_hook\n",
      "_register_state_dict_hook\n",
      "_replicate_for_data_parallel\n",
      "_save_to_state_dict\n",
      "_slow_forward\n",
      "_version\n",
      "_wrapped_call_impl\n",
      "add_module\n",
      "apply\n",
      "bfloat16\n",
      "buffers\n",
      "call_super_init\n",
      "children\n",
      "compile\n",
      "cpu\n",
      "cuda\n",
      "double\n",
      "dump_patches\n",
      "eval\n",
      "extra_repr\n",
      "float\n",
      "forward\n",
      "get_buffer\n",
      "get_extra_state\n",
      "get_parameter\n",
      "get_submodule\n",
      "half\n",
      "ipu\n",
      "load_state_dict\n",
      "modules\n",
      "named_buffers\n",
      "named_children\n",
      "named_modules\n",
      "named_parameters\n",
      "parameters\n",
      "register_backward_hook\n",
      "register_buffer\n",
      "register_forward_hook\n",
      "register_forward_pre_hook\n",
      "register_full_backward_hook\n",
      "register_full_backward_pre_hook\n",
      "register_load_state_dict_post_hook\n",
      "register_module\n",
      "register_parameter\n",
      "register_state_dict_pre_hook\n",
      "requires_grad_\n",
      "reset_parameters\n",
      "set_extra_state\n",
      "share_memory\n",
      "state_dict\n",
      "to\n",
      "to_empty\n",
      "train\n",
      "type\n",
      "xpu\n",
      "zero_grad\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "itt=dir(nn.Conv1d)\n",
    "for i in itt:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some test for the inspector library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies a 1D convolution over an input signal composed of several input\n",
      "planes.\n",
      "\n",
      "In the simplest case, the output value of the layer with input size\n",
      ":math:`(N, C_{\\text{in}}, L)` and output :math:`(N, C_{\\text{out}}, L_{\\text{out}})` can be\n",
      "precisely described as:\n",
      "\n",
      ".. math::\n",
      "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      "    \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
      "    \\star \\text{input}(N_i, k)\n",
      "\n",
      "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
      ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      ":math:`L` is a length of signal sequence.\n",
      "\n",
      "\n",
      "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      "\n",
      "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
      "  number or a one-element tuple.\n",
      "\n",
      "* :attr:`padding` controls the amount of padding applied to the input. It\n",
      "  can be either a string {'valid', 'same'} or a tuple of ints giving the\n",
      "  amount of implicit padding applied on both sides.\n",
      "\n",
      "* :attr:`dilation` controls the spacing between the kernel points; also\n",
      "  known as the à trous algorithm. It is harder to describe, but this `link`_\n",
      "  has a nice visualization of what :attr:`dilation` does.\n",
      "\n",
      "* :attr:`groups` controls the connections between inputs and outputs.\n",
      "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      "  :attr:`groups`. For example,\n",
      "\n",
      "    * At groups=1, all inputs are convolved to all outputs.\n",
      "    * At groups=2, the operation becomes equivalent to having two conv\n",
      "      layers side by side, each seeing half the input channels\n",
      "      and producing half the output channels, and both subsequently\n",
      "      concatenated.\n",
      "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      "      its own set of filters (of size\n",
      "      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
      "\n",
      "Note:\n",
      "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      "    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
      "\n",
      "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
      "    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
      "    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
      "Note:\n",
      "    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "\n",
      "Note:\n",
      "    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      "    the input so the output has the shape as the input. However, this mode\n",
      "    doesn't support any stride values other than 1.\n",
      "\n",
      "Note:\n",
      "    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
      "\n",
      "Args:\n",
      "    in_channels (int): Number of channels in the input image\n",
      "    out_channels (int): Number of channels produced by the convolution\n",
      "    kernel_size (int or tuple): Size of the convolving kernel\n",
      "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      "    padding (int, tuple or str, optional): Padding added to both sides of\n",
      "        the input. Default: 0\n",
      "    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
      "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
      "    dilation (int or tuple, optional): Spacing between kernel\n",
      "        elements. Default: 1\n",
      "    groups (int, optional): Number of blocked connections from input\n",
      "        channels to output channels. Default: 1\n",
      "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
      "        output. Default: ``True``\n",
      "\n",
      "\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n",
      "    - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n",
      "\n",
      "      .. math::\n",
      "          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n",
      "                    \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
      "\n",
      "Attributes:\n",
      "    weight (Tensor): the learnable weights of the module of shape\n",
      "        :math:`(\\text{out\\_channels},\n",
      "        \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n",
      "        The values of these weights are sampled from\n",
      "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
      "    bias (Tensor):   the learnable bias of the module of shape\n",
      "        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n",
      "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
      "    >>> input = torch.randn(20, 16, 50)\n",
      "    >>> output = m(input)\n",
      "\n",
      ".. _cross-correlation:\n",
      "    https://en.wikipedia.org/wiki/Cross-correlation\n",
      "\n",
      ".. _link:\n",
      "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "print(inspect.cleandoc(inspect.getdoc(nn.Conv1d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels\n",
      "<class 'int'>\n",
      "out_channels\n",
      "<class 'int'>\n",
      "groups\n",
      "<class 'int'>\n",
      "bias\n",
      "<class 'bool'>\n",
      "padding_mode\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "annotationslist=[type(1),type('a'),type(True)]\n",
    "\n",
    "inspector =inspect.signature(nn.Conv1d).parameters\n",
    "for i in inspector:\n",
    "    if(\n",
    "        (inspector[i].kind==inspect._ParameterKind.POSITIONAL_OR_KEYWORD) \n",
    "        and\n",
    "        (inspector[i].annotation in annotationslist )\n",
    "        ):\n",
    "        print(inspector[i].name)\n",
    "        # print(inspector[i].default)\n",
    "        print(inspector[i].annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
